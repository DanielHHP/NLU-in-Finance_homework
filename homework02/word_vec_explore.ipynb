{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from WordEmbedding.word2vec import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran out of input\n",
      "total loading time:0:00:24.023121\n",
      "词汇数:1151245\n",
      "维度数:200\n",
      "(1151245, 200)\n"
     ]
    }
   ],
   "source": [
    "w2v = word2vec('./Data/word2vec.pklz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task1：从词向量中挖掘出自己感兴趣的知识库\n",
    "\n",
    "我们从词向量汇中可以发现很多像“知识图谱中两点一线的关系”。就比如，我们可以发现“公司：CEO=小米：雷军”，而继续用“小米：雷军”可以获得“格力：董明珠”。\n",
    "\n",
    "请你像寻找公司与公司负责人建立知识库的方式，建立一个你自己感兴趣的知识库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "联想:\n",
      "     柳传志:(51.981%)\n",
      "阿里巴巴:\n",
      "     马云:(58.880%)\n",
      "百度:\n",
      "     李彦宏:(60.104%)\n",
      "新浪:\n",
      "     马云:(54.569%)\n",
      "华为:\n",
      "     任正非:(54.163%)\n",
      "滴滴:\n",
      "     程维:(55.551%)\n",
      "搜狐:\n",
      "     张朝阳:(49.061%)\n",
      "网易:\n",
      "     丁磊:(54.324%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 寻找公司CEO\n",
    "print_word_statistics(w2v.analogy('腾讯', '马化腾', ['联想', '阿里巴巴', '百度', '新浪', '华为', '滴滴', '搜狐', '网易'], 1, []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['上海', '清迈', '成都', '广州', '天津', '深圳', '泰国', '吉隆坡', '孟买', '迪拜', '武汉', '西安', '首尔', '首都', '杭州', '东京', '新德里', '厦门', '台北', '暹粒']\n",
      "['上海', '成都', '西安', '杭州', '天津', '深圳', '南京', '武汉', '广州', '重庆', '苏州', '石家庄', '昆明', '上海浦东', '郑州', '帝都', '厦门', '济南']\n",
      "枚举与菲律宾、泰国相似概念的实体…印尼:(82.283%)\n",
      "马来西亚:(79.639%)\n",
      "越南:(78.909%)\n",
      "柬埔寨:(77.448%)\n",
      "印度尼西亚:(76.954%)\n",
      "斯里兰卡:(73.214%)\n",
      "马尼拉:(68.980%)\n",
      "澳大利亚:(68.966%)\n",
      "老挝:(68.370%)\n",
      "缅甸:(67.854%)\n",
      "黎巴嫩:(67.539%)\n",
      "南非:(66.841%)\n",
      "新加坡:(66.613%)\n",
      "约旦:(66.454%)\n",
      "墨西哥:(66.181%)\n",
      "韩国:(66.072%)\n",
      "印度:(65.904%)\n",
      "日本:(65.737%)\n",
      "马来:(65.432%)\n",
      "曼谷:(65.158%)\n",
      "印尼=>雅加达. sim:[[ 0.73682109]]\n",
      "马来西亚=>吉隆坡. sim:[[ 0.64849586]]\n",
      "越南=>河内. sim:[[ 0.74702608]]\n",
      "柬埔寨=>河内. sim:[[ 0.65985945]]\n",
      "印度尼西亚=>雅加达. sim:[[ 0.67632078]]\n",
      "斯里兰卡=>科伦坡. sim:[[ 0.70817904]]\n",
      "马尼拉=>华盛顿. sim:[[ 0.53562211]]\n",
      "澳大利亚=>堪培拉. sim:[[ 0.66363352]]\n",
      "老挝=>河内. sim:[[ 0.63268439]]\n",
      "缅甸=>仰光. sim:[[ 0.72669249]]\n",
      "黎巴嫩=>安曼. sim:[[ 0.59190955]]\n",
      "南非=>开普敦. sim:[[ 0.7225216]]\n",
      "新加坡=>曼谷. sim:[[ 0.57556231]]\n",
      "约旦=>黎巴嫩. sim:[[ 0.85692715]]\n",
      "墨西哥=>圣保罗. sim:[[ 0.65570954]]\n",
      "韩国=>首尔. sim:[[ 0.68146052]]\n",
      "印度=>新德里. sim:[[ 0.68090484]]\n",
      "日本=>东京. sim:[[ 0.62974633]]\n",
      "马来=>兰卡威. sim:[[ 0.59626056]]\n",
      "曼谷=>清迈. sim:[[ 0.83615004]]\n"
     ]
    }
   ],
   "source": [
    "    answer = w2v.get_enumerator(\"菲律宾\", \"泰国\", 20)\n",
    "    cptitals = [item[0] for item in w2v.get_enumerator(\"北京\", \"曼谷\", 20)]\n",
    "    print(cptitals)\n",
    "    # 比较一下这个\n",
    "    cptitals = [item[0] for item in w2v.get_enumerator2(\"北京\", \"曼谷\", \"菲律宾\", 20)]  # 找与北京曼谷相似的，但是要把国家排除\n",
    "    print(cptitals)\n",
    "\n",
    "    print('枚举与菲律宾、泰国相似概念的实体…' + print_word_statistics(answer, False))\n",
    "\n",
    "    capital_country = w2v[\"华盛顿\"] - w2v[\"美国\"]  # 建构首都与国家关系式(可以试试不同建构方式)\n",
    "\n",
    "    for item in answer:\n",
    "        country = item[0]\n",
    "        capital = w2v[item[0]] + capital_country\n",
    "        for similarword in w2v.find_nearest_word(capital, 5):\n",
    "            if str(similarword[0]) != country or similarword[0] in cptitals:\n",
    "                print(country + \"=>\" + similarword[0]  + \". sim:\" + str(w2v.cosine_similarity(country, similarword[0])))\n",
    "                break\n",
    "                # 有没有甚么好办法可以筛选的更精确?\n",
    "                # 能否设计出其他的透过词向量拓展知识图谱的ˊ类似方法流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task2：从词向量中发现出乎意料的“同义词”！\n",
    "\n",
    "有时候我们试图用类比的方式去寻找一些“同义词”，却得到了意外的收获。比如：\n",
    "“西红柿：番茄=张惠妹：？”我们认为答案应该是“阿妹”，但是我们却收到了意外的答案：“蔡依林”。这可能是因为“西红柿”是比较本土的称呼，而“番茄”是海外传来的叫法，而我们知道张惠妹是台湾的原住民，也就是本土……\n",
    "\n",
    "我们以为番茄之与西红柿是昵称的关系，但是词向量空间好像发现了它们不同角度的含义，这其实是语义空间非常值得玩味的地方。所以我们的任务就是去发现这样令你意外的“同义词”，并且试着去分析，找出来词为什么不是你想要的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "手机:\n",
      "     智能手机:(69.963%)\n",
      "     机子:(63.485%)\n",
      "     智能机:(62.324%)\n",
      "公交车:\n",
      "     公共汽车:(72.304%)\n",
      "     电车:(65.244%)\n",
      "     公汽:(65.068%)\n",
      "电脑:\n",
      "     笔记本电脑:(63.553%)\n",
      "     pad:(61.244%)\n",
      "     平板:(59.973%)\n",
      "电视:\n",
      "     网络电视:(65.669%)\n",
      "     机顶盒:(60.301%)\n",
      "     微鲸:(59.778%)\n",
      "摩托车:\n",
      "     三轮车:(68.754%)\n",
      "     三轮摩托:(66.743%)\n",
      "     自行车:(66.167%)\n",
      "高兴:\n",
      "     开心:(75.534%)\n",
      "     欣慰:(67.056%)\n",
      "     十分高兴:(64.911%)\n",
      "很大:\n",
      "     相当大:(82.638%)\n",
      "     不小:(73.124%)\n",
      "     并不大:(68.375%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 寻找同义词\n",
    "print_word_statistics(w2v.analogy('西红柿', '番茄', ['手机', '公交车', '电脑', '电视', '摩托车', '高兴', '很大'], 3, []))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "词向量考虑了很多上下文关系，所以在同义发现上其实是倾向于找到上下文与给定输入向量差异相近的词，“摩托车”和“三轮车”的用法与“番茄”和“西红柿”的用法类似，所以得出了这个结果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
